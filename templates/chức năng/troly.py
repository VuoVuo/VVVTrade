import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from dotenv import load_dotenv

# Load API key
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# Set up Streamlit app
st.set_page_config(page_title="Trá»£ lÃ½ TÃ i chÃ­nh AI", layout="wide")
st.title("ğŸ¤– Trá»£ lÃ½ TÃ i chÃ­nh AI - Äá»c & Há»c tá»« TÃ i liá»‡u")

uploaded_file = st.file_uploader("Táº£i lÃªn tÃ i liá»‡u PDF vá» phÆ°Æ¡ng phÃ¡p trade hoáº·c tÃ i chÃ­nh:", type="pdf")

if uploaded_file:
    with st.spinner("Äang Ä‘á»c tÃ i liá»‡u..."):
        loader = PyPDFLoader(uploaded_file.name)
        pages = loader.load()

        # Cáº¯t nhá» vÄƒn báº£n
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        documents = text_splitter.split_documents(pages)

        # Táº¡o embeddings vÃ  vector store
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        vectordb = Chroma.from_documents(documents, embedding=embeddings, persist_directory="db")
        vectordb.persist()

        # Táº¡o chuá»—i truy váº¥n
        llm = ChatOpenAI(model_name="gpt-4", temperature=0, openai_api_key=openai_api_key)
        qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever())

        st.success("TÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½! BÃ¢y giá» báº¡n cÃ³ thá»ƒ há»i báº¥t ká»³ Ä‘iá»u gÃ¬ tá»« nÃ³.")

        query = st.text_input("HÃ£y nháº­p cÃ¢u há»i vá» tÃ i liá»‡u báº¡n vá»«a upload:")
        if query:
            with st.spinner("Äang tráº£ lá»i..."):
                result = qa_chain.run(query)
                st.write(result)
else:
    st.info("HÃ£y upload má»™t file PDF Ä‘á»ƒ báº¯t Ä‘áº§u.")
